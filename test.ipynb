{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY TO ADD DROPOUT\n",
    "\n",
    "class FaceSubnet(nn.Module):\n",
    "\n",
    "    def __init__(self, seed=13):\n",
    "        super(FaceSubnet, self).__init__()\n",
    "#         torch.manual_seed(seed)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=96)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_features=256 * 7 * 7, out_features=4096)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.fc8 = nn.Linear(in_features=1024, out_features=256)\n",
    "        \n",
    "        self.mpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        \n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.mpool(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.mpool(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.mpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return F.normalize(x)\n",
    "\n",
    "## TRY TO REMOVE DROPOUT\n",
    "\n",
    "class VoiceSubnet(nn.Module):\n",
    "\n",
    "    def __init__(self, seed=13):\n",
    "        super(VoiceSubnet, self).__init__()\n",
    "#         torch.manual_seed(seed)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=96)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        self.bn6 = nn.BatchNorm2d(num_features=4096)\n",
    "        \n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.fc8 = nn.Linear(in_features=1024, out_features=256)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool5 = nn.MaxPool2d(kernel_size=(5, 3), stride=(3, 2))\n",
    "        \n",
    "        # Conv2d with weights of size (H, 1) is identical to FC with H weights\n",
    "        self.fc6 = nn.Conv2d(in_channels=256, out_channels=4096, kernel_size=(9, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.mpool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.mpool2(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.mpool5(x)\n",
    "\n",
    "        B, C, H, W = x.size()\n",
    "        self.apool6 = nn.AvgPool2d(kernel_size=(1, W))\n",
    "\n",
    "        x = self.relu(self.bn6(self.fc6(x)))\n",
    "        x = self.apool6(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return F.normalize(x)\n",
    "    \n",
    "class CurriculumMining(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CurriculumMining, self).__init__()\n",
    "        \n",
    "    def forward(self, positive_pairs, tau):\n",
    "        faces, voices = positive_pairs\n",
    "        B, D = faces.size()\n",
    "        # calc dist \n",
    "        # (X - Y) ^ 2 = X^2 + Y^2 - 2XY\n",
    "        x = (faces**2).sum(dim=1).view(-1, 1) + (voices**2).sum(dim=1) - 2*faces.matmul(voices.t())\n",
    "        dists = x.sqrt()\n",
    "        \n",
    "        sorted_dist, sorted_idx = torch.sort(dists, dim=1, descending=True)\n",
    "        Dnj = sorted_dist - dists.diag().view(-1, 1)\n",
    "        idx_threshold = round(tau * (B-1))\n",
    "        \n",
    "        # tricky part\n",
    "        mask = torch.ones_like(sorted_dist)\n",
    "        mask[:, idx_threshold+1:] = 0\n",
    "        mask[Dnj <= 0] = 0\n",
    "        idx_of_sorted_idx = ((mask).sum(dim=1) - 1).abs().long()\n",
    "        neg_samples_idx = torch.gather(sorted_idx, dim=1, index=idx_of_sorted_idx.view(B, 1))\n",
    "        neg_samples_idx = neg_samples_idx.view(B)\n",
    "        negative_voices = voices[neg_samples_idx]\n",
    "        \n",
    "        return (faces, negative_voices)\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, positive_pairs, negative_pairs, margin):\n",
    "        ## POSITIVE PART\n",
    "        faces, voices = positive_pairs\n",
    "#         dists_pos = ((faces - voices) ** 2).sum(dim=1).sqrt()\n",
    "#         pos_part = dists_pos ** 2\n",
    "        pos_part = ((faces - voices) ** 2).sum(dim=1)\n",
    "    \n",
    "        ## NEGATIVE PART\n",
    "        faces, voices = negative_pairs\n",
    "        dists_neg = ((faces - voices) ** 2).sum(dim=1).sqrt()\n",
    "        neg_part = (margin - dists_neg).clamp(0) ** 2\n",
    "        \n",
    "        loss4pair = torch.cat([pos_part, neg_part])\n",
    "        \n",
    "        ## CALCULATE LOSS\n",
    "        B, D = faces.size()\n",
    "        batch_loss = loss4pair.sum() / (2 * B)\n",
    "    \n",
    "        return batch_loss\n",
    "\n",
    "class LearnablePinsNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LearnablePinsNet, self).__init__()\n",
    "        self.face_subnet = FaceSubnet()\n",
    "        self.voice_subnet = VoiceSubnet()\n",
    "        self.curr_mining = CurriculumMining()\n",
    "        \n",
    "    def forward(self, frames, log_specs, tau=None):\n",
    "        emb_f = self.face_subnet(frames)\n",
    "        emb_v = self.voice_subnet(log_specs)\n",
    "        \n",
    "        if self.training:\n",
    "            positive_pairs = (emb_f, emb_v)\n",
    "            negative_pairs = self.curr_mining(positive_pairs, tau)\n",
    "\n",
    "            return positive_pairs, negative_pairs\n",
    "        \n",
    "        else:\n",
    "            return emb_f, emb_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"Normalizes both face (mean) and voice spectogram (mean-varience)\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        frame, log_spectogram = sample\n",
    "\n",
    "        ## FACE (H, W, C)\n",
    "        # mean normalization for every image (not batch)\n",
    "        mu = frame.mean(axis=(0, 1))\n",
    "        frame = frame - mu\n",
    "        \n",
    "        ## VOICE (Freq, Time)\n",
    "        # mean-variance normalization for every spectogram (not batch)\n",
    "        mu = log_spectogram.mean(axis=1).reshape(512, 1)\n",
    "        sigma = log_spectogram.std(axis=1).reshape(512, 1)\n",
    "        log_spectogram = (log_spectogram - mu) / sigma\n",
    "\n",
    "        return frame, log_spectogram\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    '''Horizontally flip the given Image ndarray randomly with a given probability.'''\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        frame, log_spectogram = sample\n",
    "\n",
    "        if random.random() < self.p:\n",
    "            return cv2.flip(frame, 1), log_spectogram\n",
    "        \n",
    "        return frame, log_spectogram\n",
    "\n",
    "class ColorJittering(object):\n",
    "    '''Given Image ndarray performs brightness and \n",
    "    saturation jittering. It is not mentioned in the paper but I guess \n",
    "    the authors used MatConvNet but do not mention any specific augmentation\n",
    "    parameters. So, I made my wind guess regarding the parameters and implemented\n",
    "    augmentation in the following fashion as in there:\n",
    "    http://www.vlfeat.org/matconvnet/mfiles/vl_imreadjpeg/\n",
    "    and the Section 3.5 of the manual\n",
    "    http://www.vlfeat.org/matconvnet/matconvnet-manual.pdf'''\n",
    "    \n",
    "    def __init__(self, brightness=[255/25.5, 255/25.5, 255/25.5], saturation=0.5):\n",
    "        # brightness\n",
    "        self.B = np.array(brightness, dtype=np.float32)\n",
    "        # saturation\n",
    "        self.S = saturation\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        frame, log_spectogram = sample\n",
    "        \n",
    "        # brightness\n",
    "        # gives an error w/o float32 -- normal() returns float64\n",
    "        w = np.float32(np.random.normal(size=3))\n",
    "        b = self.B * w\n",
    "        frame = np.clip(frame + b, 0, 255)\n",
    "        \n",
    "        # saturation\n",
    "        sigma = np.random.uniform(1-self.S, 1+self.S)\n",
    "        frame = sigma * frame + (1-sigma) / 3 * frame.sum(axis=2, keepdims=True)\n",
    "        frame = np.clip(frame, 0, 255)\n",
    "        \n",
    "        return frame, log_spectogram\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        frame, log_spectogram = sample\n",
    "        F, T = log_spectogram.shape\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        frame = frame.transpose((2, 0, 1))\n",
    "        \n",
    "        # now log_specs are of size (Freq, Time) 2D but has to be 3D\n",
    "        log_spectogram = log_spectogram.reshape(1, F, T)\n",
    "\n",
    "        return torch.from_numpy(frame), torch.from_numpy(log_spectogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFrameDatasetTest(Dataset):\n",
    "    '''Test only'''\n",
    "\n",
    "    def __init__(self, path_to_data, path_to_pairs, transform=None): \n",
    "        self.path_to_data = path_to_data\n",
    "        self.transform = transform\n",
    "        self.dataset = pd.read_table(path_to_pairs, sep=',')[['label', 'voice-path', 'face-path']]\n",
    "        self.dataset.replace({'_000': '/0'}, inplace=True, regex=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, voice_path, face_path = self.dataset.iloc[idx]\n",
    "        \n",
    "        ### VISUAL INPUT\n",
    "        full_face_path = os.path.join(self.path_to_data, 'video', face_path)\n",
    "        frame = cv2.cvtColor(cv2.imread(full_face_path), cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        ### AUDIO INPUT\n",
    "        # not 1024 as reported in the referenced paper [35] \n",
    "        # because it gives 513xN but not 512xN\n",
    "        FFT_len = 1022\n",
    "        window = 'hamming'\n",
    "        full_voice_path = os.path.join(self.path_to_data, 'audio', voice_path)\n",
    "\n",
    "        sample_rate, samples = wavfile.read(full_voice_path)\n",
    "        window_width = int(sample_rate * 0.025)\n",
    "        overlap = int(sample_rate * (0.025 - 0.010))\n",
    "        audio_segment = samples\n",
    "        _, _, spectrogram = signal.spectrogram(audio_segment, sample_rate, \n",
    "                                               window=window, nfft=FFT_len, \n",
    "                                               nperseg=window_width, noverlap=overlap, \n",
    "                                               mode='magnitude')\n",
    "#         log_spectogram = np.log(spectrogram)\n",
    "        log_spectogram = spectrogram.copy()\n",
    "        assert sample_rate == 16000\n",
    "        \n",
    "        if self.transform:\n",
    "            frame = frame.astype(np.float32)\n",
    "            log_spectogram = log_spectogram.astype(np.float32)\n",
    "            frame, log_spectogram = self.transform((frame, log_spectogram))\n",
    "\n",
    "        return (label, frame, log_spectogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = '/home/vladimir/storage8tb/logs/LearnablePINs4/'\n",
    "DATA_PATH = '/home/vladimir/storage8tb/data/voxceleb1/'\n",
    "FACE_SUBNET_SNAPSHOT_PATH = os.path.join(LOG_PATH, 'face_subnet_snapshot.txt')\n",
    "VOICE_SUBNET_SNAPSHOT_PATH = os.path.join(LOG_PATH, 'voice_subnet_snapshot.txt')\n",
    "DEVICES = [0, 2]\n",
    "# since audio tracks may have different lengths the computation cannot be \n",
    "# made in batches larger than 1 per device\n",
    "B = len(DEVICES)\n",
    "B = 1\n",
    "# https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/5\n",
    "NUM_WORKERS = 4 * len(DEVICES)\n",
    "MARGIN = 0.6\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'testpairs/testpairs')\n",
    "TEST_RANDOM_SH = os.path.join(TEST_PATH, 'veriflist_test_random_seenheard.txt')\n",
    "TEST_RANDOM_UU = os.path.join(TEST_PATH, 'veriflist_test_random_unseenunheard.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = Compose([\n",
    "    Normalize(),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "test = AudioFrameDatasetTest(DATA_PATH, TEST_RANDOM_SH, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=B, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LearnablePinsNet()\n",
    "net.face_subnet.load_state_dict(torch.load(FACE_SUBNET_SNAPSHOT_PATH))\n",
    "net.voice_subnet.load_state_dict(torch.load(VOICE_SUBNET_SNAPSHOT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "torch.cuda.set_device(DEVICES[0])\n",
    "net.to(device);\n",
    "# net = nn.DataParallel(net, DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 32.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3202], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3194], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3223], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3209], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0305], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0359], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0296], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0295], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3176], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3168], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3199], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3158], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3215], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3151], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:00, 47.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3216], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3211], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0342], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0445], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0357], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0400], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3178], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3243], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3170], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3171], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3107], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3212], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3113], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3148], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0286], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0272], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0269], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 62.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0277], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3098], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3195], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3101], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3161], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3114], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3174], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3118], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3123], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3210], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3214], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3247], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3210], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0440], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0473], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0432], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:00, 70.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0450], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3229], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3160], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3205], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3151], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1585], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1573], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1586], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1599], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0263], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0389], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0328], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0293], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3180], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3152], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3195], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3109], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.2335], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.2222], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.2305], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:00, 84.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2275], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0861], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0818], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0833], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0824], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0299], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0366], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0326], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0361], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1143], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1088], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1121], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1121], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3187], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3114], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3191], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3167], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3162], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3172], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3154], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3111], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:01, 91.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3170], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3113], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3165], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3112], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3187], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3152], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3188], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3129], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3189], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3227], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3181], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3157], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3198], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3171], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3202], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3106], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3236], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3183], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3233], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3132], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:01, 94.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3229], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3174], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3246], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3186], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3215], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3155], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3198], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3114], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3184], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3119], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3207], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3151], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0291], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0296], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0289], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.0295], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3172], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3105], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3165], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3216], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3128], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [00:01, 101.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3185], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3115], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3130], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3247], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3265], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3177], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3220], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3144], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3229], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3137], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3173], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3153], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3141], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3127], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3161], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3146], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3172], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3116], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3110], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1927], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1865], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1879], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.1907], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:01, 103.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3147], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3180], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3185], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3210], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3111], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3146], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3139], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3198], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3200], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3147], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3213], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3224], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3240], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3174], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3211], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3187], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3199], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3179], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3208], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3119], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3197], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "189it [00:02, 98.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3214], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3237], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3192], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3184], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3137], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3190], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3175], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3281], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3232], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3270], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3274], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3212], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3163], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3196], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3122], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3209], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3149], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3165], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3196], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3232], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "209it [00:02, 89.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3122], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3201], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3164], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3197], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3162], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3206], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3139], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3155], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3141], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3185], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3105], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3240], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3180], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3238], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3193], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3207], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3242], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:02, 94.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3214], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3197], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3053], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3000], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3092], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3016], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3213], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3196], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3182], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3168], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3176], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3118], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3164], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3116], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3176], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3158], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3185], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3144], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3175], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3180], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [00:02, 99.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3152], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3104], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3177], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3196], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3164], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3146], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3189], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3171], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3183], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3129], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3182], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3134], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3218], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3173], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3183], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3108], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3138], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3112], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3209], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3188], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3209], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "tensor([0.3191], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Process Process-1:\n",
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"<ipython-input-4-fb0b9bab6f8b>\", line 35, in __getitem__\n",
      "    mode='magnitude')\n",
      "  File \"<ipython-input-4-fb0b9bab6f8b>\", line 19, in __getitem__\n",
      "    frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/scipy/signal/spectral.py\", line 710, in spectrogram\n",
      "    Sxx = np.abs(Sxx)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vladimir/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8cb050402a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_specs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0memb_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9eaf5752e238>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, frames, log_specs, tau)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0memb_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0memb_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoice_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9eaf5752e238>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "results = pd.DataFrame(columns=['predict', 'label'])\n",
    "\n",
    "for i, (labels, frames, log_specs) in tqdm(enumerate(testloader)):\n",
    "    frames, log_specs = frames.cuda(async=True), log_specs.cuda(async=True)\n",
    "    \n",
    "    emb_f, emb_v = net(frames, log_specs)\n",
    "    \n",
    "    dists = torch.pairwise_distance(emb_f, emb_v)\n",
    "    \n",
    "    predict = dists < MARGIN\n",
    "    \n",
    "    batch_preds_labels = pd.DataFrame([\n",
    "        pd.Series(predict, name='predict'), \n",
    "        pd.Series(labels, name='label')\n",
    "    ]).transpose()\n",
    "    \n",
    "    results = results.append(batch_preds_labels, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

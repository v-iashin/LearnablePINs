{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `1.6/` folder from `unzippedFaces`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basedir = '/media/storage8tb/data/voxceleb1/unzippedFaces/'\n",
    "\n",
    "# list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = basedir + folder\n",
    "    \n",
    "#     for folder2 in os.listdir(root + '/1.6/'):\n",
    "#         shutil.move(root + '/1.6/' + folder2, os.path.join(root, folder2))\n",
    "        \n",
    "#     os.rmdir(root + '/1.6/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VoxCeleb1 ID</th>\n",
       "      <th>VGGFace1 ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10001</td>\n",
       "      <td>A.J._Buckley</td>\n",
       "      <td>m</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10002</td>\n",
       "      <td>A.R._Rahman</td>\n",
       "      <td>m</td>\n",
       "      <td>India</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10003</td>\n",
       "      <td>Aamir_Khan</td>\n",
       "      <td>m</td>\n",
       "      <td>India</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10004</td>\n",
       "      <td>Aaron_Tveit</td>\n",
       "      <td>m</td>\n",
       "      <td>USA</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10005</td>\n",
       "      <td>Aaron_Yoo</td>\n",
       "      <td>m</td>\n",
       "      <td>USA</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VoxCeleb1 ID   VGGFace1 ID Gender Nationality  Set\n",
       "0      id10001  A.J._Buckley      m     Ireland  dev\n",
       "1      id10002   A.R._Rahman      m       India  dev\n",
       "2      id10003    Aamir_Khan      m       India  dev\n",
       "3      id10004   Aaron_Tveit      m         USA  dev\n",
       "4      id10005     Aaron_Yoo      m         USA  dev"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv('/media/storage8tb/data/voxceleb1/metadata/vox1_meta.csv', sep='\\t')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name2id = meta.set_index('VGGFace1 ID')['VoxCeleb1 ID'].to_dict()\n",
    "\n",
    "# ### AUDIO ###\n",
    "# basedir = '/media/storage8tb/data/voxceleb1/audio/'\n",
    "\n",
    "# list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = basedir + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = name2id[folder]\n",
    "#     os.rename(basedir + prev_name, basedir + new_name)\n",
    "    \n",
    "# ### VIDEO ###\n",
    "# basedir = '/media/storage8tb/data/voxceleb1/video/'\n",
    "\n",
    "# list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = basedir + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = name2id[folder]\n",
    "#     os.rename(basedir + prev_name, basedir + new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2name = meta.set_index('VoxCeleb1 ID')['VGGFace1 ID'].to_dict()\n",
    "\n",
    "# ### AUDIO ###\n",
    "# basedir = '/media/storage8tb/data/voxceleb1/audio/'\n",
    "\n",
    "# list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = basedir + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = id2name[folder]\n",
    "#     os.rename(basedir + prev_name, basedir + new_name)\n",
    "\n",
    "# ### VIDEO ###\n",
    "# basedir = '/media/storage8tb/data/voxceleb1/video/'\n",
    "\n",
    "# list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = basedir + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = id2name[folder]\n",
    "#     os.rename(basedir + prev_name, basedir + new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tracks from `voice_set_labels.txt` (i.e. dataset) which does not have frames in `zippedFaces.tar.gz`. Note, that the _\"we should never have more than 20 frames in a sequence from the same track\"_ is taken into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/media/storage8tb/data/voxceleb1/'\n",
    "path_to_split = '/media/storage8tb/data/voxceleb1/Splits/voice_set_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## outputs a file `still_missing_frames.txt` with missing frames\n",
    "\n",
    "# still_missing_frames_savepath = '/home/vladimir/Desktop/still_missing_frames.txt'\n",
    "\n",
    "# still_missing_frames = []\n",
    "\n",
    "# voice_set_labels = pd.read_table(path_to_split, sep=' ', names=['path', 'phase'])\n",
    "# voice_set_labels.replace({'_000': '/0', '.wav$': ''}, inplace=True, regex=True)\n",
    "\n",
    "# for path in tqdm(voice_set_labels['path']):\n",
    "#     video_path = os.path.join(path_to_data, 'video', path + '.txt')\n",
    "    \n",
    "#     if os.path.isfile(os.path.join(path_to_data, 'audio', path + '.wav')):\n",
    "#         frames = pd.read_table(video_path, skiprows=6, usecols=['FRAME '])\n",
    "        \n",
    "#     earliest = frames['FRAME '].iloc[0]\n",
    "#     latest = frames['FRAME '].iloc[-1]\n",
    "#     frame_list = np.arange(earliest, latest+1)\n",
    "#     mask = np.where(frame_list % 25 == 0)\n",
    "#     frames_sec = frame_list[mask]\n",
    "#     # only 20 per each face-track (see the asterics on the project page)\n",
    "#     # frames_sec = frame_list[mask]\n",
    "#     frames_sec = frame_list[mask][:20]\n",
    "    \n",
    "#     for frame_number in frames_sec:\n",
    "#         filename ='{0:07d}.jpg'.format(frame_number)\n",
    "#         selected_frame_path = os.path.join(path_to_data, 'video', path[:-5] + filename)\n",
    "        \n",
    "#         if os.path.isfile(selected_frame_path):\n",
    "#             continue\n",
    "            \n",
    "#         else:\n",
    "#             still_missing_frames.append(selected_frame_path[39:])\n",
    "            \n",
    "# with open(still_missing_frames_savepath, 'w') as out_f:\n",
    "#     for file in still_missing_frames:\n",
    "#         out_f.write(file + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153486/153486 [03:45<00:00, 679.58it/s]\n"
     ]
    }
   ],
   "source": [
    "## outputs unique tracks that have at least one frame missing. \n",
    "\n",
    "tracks_to_filter_path = '/home/vladimir/Desktop/tracks_to_filter.txt'\n",
    "\n",
    "tracks_to_filter = []\n",
    "\n",
    "voice_set_labels = pd.read_table(path_to_split, sep=' ', names=['path', 'phase'])\n",
    "voice_set_labels.replace({'_000': '/0', '.wav$': ''}, inplace=True, regex=True)\n",
    "\n",
    "for path in tqdm(voice_set_labels['path']):\n",
    "    video_path = os.path.join(path_to_data, 'video', path + '.txt')\n",
    "    \n",
    "    if os.path.isfile(os.path.join(path_to_data, 'audio', path + '.wav')):\n",
    "        frames = pd.read_table(video_path, skiprows=6, usecols=['FRAME '])\n",
    "        \n",
    "    earliest = frames['FRAME '].iloc[0]\n",
    "    latest = frames['FRAME '].iloc[-1]\n",
    "    frame_list = np.arange(earliest, latest+1)\n",
    "    mask = np.where(frame_list % 25 == 0)\n",
    "    frames_sec = frame_list[mask]\n",
    "    # only 20 per each face-track (see the asterics on the project page)\n",
    "    # frames_sec = frame_list[mask]\n",
    "    frames_sec = frame_list[mask][:20]\n",
    "    \n",
    "    for frame_number in frames_sec:\n",
    "        filename ='{0:07d}.jpg'.format(frame_number)\n",
    "        selected_frame_path = os.path.join(path_to_data, 'video', path[:-5] + filename)\n",
    "        \n",
    "        if os.path.isfile(selected_frame_path):\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            # remove dir path and file extention\n",
    "            tracks_to_filter.append(video_path[39:])\n",
    "            break\n",
    "            \n",
    "with open(tracks_to_filter_path, 'w') as out_f:\n",
    "    for file in tracks_to_filter:\n",
    "        out_f.write(file + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "153486 - len(tracks_to_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153486it [00:00, 485618.85it/s]\n"
     ]
    }
   ],
   "source": [
    "mask = voice_set_labels['path'].apply(lambda x: x in tracks_to_filter)\n",
    "indices = voice_set_labels[mask].index\n",
    "\n",
    "filteredpath = os.path.join(path_to_data, 'Splits', 'filtered_voice_set_labels.txt')\n",
    "\n",
    "with open(path_to_split, 'r') as r, open(filteredpath, 'w') as w:\n",
    "    \n",
    "    for idx, line in enumerate(r.readlines()):\n",
    "        \n",
    "        if idx not in indices:\n",
    "            w.write(line)\n",
    "        \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## which phases the missing files belong to (1 and 3 -- train and seen test)\n",
    "print(voice_set_labels[mask]['phase'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Corbin_Bleu/fXwfYa_uUZw/00003' in tracks_to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.J._Buckley/Y8hIVOBuels_0000001\n",
      "A.J._Buckley/Y8hIVOBuels_0000002\n",
      "A.J._Buckley/Y8hIVOBuels_0000003\n",
      "A.J._Buckley/Y8hIVOBuels_0000004\n"
     ]
    }
   ],
   "source": [
    "## remove these tracks from the `voice_set_labels.txt` and write the rest to a new file\n",
    "\n",
    "filteredpath = os.path.join(path_to_data, 'Splits', 'filtered_voice_set_labels.txt')\n",
    "i = 0\n",
    "with open(path_to_split, 'r') as r, open(filteredpath, 'w') as w:\n",
    "    \n",
    "    for line in r.readlines():\n",
    "        path, _ = line.split('.wav ')\n",
    "        print(path)\n",
    "        i += 1\n",
    "        \n",
    "        if i > 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

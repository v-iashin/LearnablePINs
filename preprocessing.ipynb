{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that `zippedFaces.tar.gz`, merged `vox1_dev_wav.zip`, test set `vox1_test_wav.zip`, textual video frames `vox1_dev_txt.zip` and `vox1_test_txt.zip`, as well as files with splits `Splits.zip`, test pairs `testpairs.zip`  and meta information files are located in `DATA_FOLDER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/hdd/data/voxceleb1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPPED_FACES_PATH = os.path.join(DATA_PATH, 'zippedFaces.tar.gz')\n",
    "\n",
    "AUDIO_DEV_PATH = os.path.join(DATA_PATH, 'vox1_dev_wav.zip')\n",
    "AUDIO_TEST_PATH = os.path.join(DATA_PATH, 'vox1_test_wav.zip')\n",
    "VIDEO_TXT_DEV_PATH = os.path.join(DATA_PATH, 'vox1_dev_txt.zip')\n",
    "VIDEO_TXT_TEST_PATH = os.path.join(DATA_PATH, 'vox1_test_txt.zip')\n",
    "SPLIT_ZIP_PATH = os.path.join(DATA_PATH, 'Splits.zip')\n",
    "TESTPAIRS_ZIP_PATH = os.path.join(DATA_PATH, 'testpairs.zip')\n",
    "\n",
    "AUDIO_PATH = os.path.join(DATA_PATH, 'audio/')\n",
    "VIDEO_PATH = os.path.join(DATA_PATH, 'video/')\n",
    "VIDEO_TXT_PATH = os.path.join(DATA_PATH, 'txt/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the content of the archives and change the folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to unpack zippedFaces.tar.gz\n",
      "Done. Starting to unpack vox1_dev_wav.zip\n",
      "Done. Starting to unpack vox1_test_wav.zip\n",
      "Done. Staring to unpack vox1_dev_txt.zip and vox1_test_txt.zip\n",
      "Done. Staring to unpack Splits.zip and testpairs.zip\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Starting to unpack zippedFaces.tar.gz')\n",
    "tar = tarfile.open(ZIPPED_FACES_PATH)\n",
    "tar.extractall(DATA_PATH)\n",
    "tar.close()\n",
    "print('Done. Starting to unpack vox1_dev_wav.zip')\n",
    "zip = zipfile.ZipFile(AUDIO_DEV_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "print('Done. Starting to unpack vox1_test_wav.zip')\n",
    "zip = zipfile.ZipFile(AUDIO_TEST_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "print('Done. Staring to unpack vox1_dev_txt.zip and vox1_test_txt.zip')\n",
    "zip = zipfile.ZipFile(VIDEO_TXT_DEV_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "zip = zipfile.ZipFile(VIDEO_TXT_TEST_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "print('Done. Staring to unpack Splits.zip and testpairs.zip')\n",
    "zip = zipfile.ZipFile(SPLIT_ZIP_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "zip = zipfile.ZipFile(TESTPAIRS_ZIP_PATH, 'r')\n",
    "zip.extractall(DATA_PATH)\n",
    "zip.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(os.path.join(DATA_PATH, 'wav'), AUDIO_PATH)\n",
    "os.rename(os.path.join(DATA_PATH, 'unzippedFaces'), VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `1.6/` folder from `video` (prev. `unzippedFaces`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:06<00:00, 180.77it/s]\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(DATA_PATH, 'video/')\n",
    "\n",
    "list_of_dirs = os.listdir(basedir)\n",
    "\n",
    "for folder in tqdm(list_of_dirs):\n",
    "    root = basedir + folder\n",
    "    \n",
    "    for folder2 in os.listdir(root + '/1.6/'):\n",
    "        shutil.move(root + '/1.6/' + folder2, os.path.join(root, folder2))\n",
    "        \n",
    "    os.rmdir(root + '/1.6/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename identity folders `id00**` to real celebrity names in `txt` and `audio` folders. First, we need to load the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VoxCeleb1 ID</th>\n",
       "      <th>VGGFace1 ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10001</td>\n",
       "      <td>A.J._Buckley</td>\n",
       "      <td>m</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10002</td>\n",
       "      <td>A.R._Rahman</td>\n",
       "      <td>m</td>\n",
       "      <td>India</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10003</td>\n",
       "      <td>Aamir_Khan</td>\n",
       "      <td>m</td>\n",
       "      <td>India</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10004</td>\n",
       "      <td>Aaron_Tveit</td>\n",
       "      <td>m</td>\n",
       "      <td>USA</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10005</td>\n",
       "      <td>Aaron_Yoo</td>\n",
       "      <td>m</td>\n",
       "      <td>USA</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VoxCeleb1 ID   VGGFace1 ID Gender Nationality  Set\n",
       "0      id10001  A.J._Buckley      m     Ireland  dev\n",
       "1      id10002   A.R._Rahman      m       India  dev\n",
       "2      id10003    Aamir_Khan      m       India  dev\n",
       "3      id10004   Aaron_Tveit      m         USA  dev\n",
       "4      id10005     Aaron_Yoo      m         USA  dev"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(os.path.join(DATA_PATH, 'vox1_meta.csv'), sep='\\t')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id001** to Real Celebrity's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:00<00:00, 109043.71it/s]\n",
      "100%|██████████| 1251/1251 [00:01<00:00, 662.15it/s]\n"
     ]
    }
   ],
   "source": [
    "id2name = meta.set_index('VoxCeleb1 ID')['VGGFace1 ID'].to_dict()\n",
    "\n",
    "### AUDIO ###\n",
    "list_of_dirs = os.listdir(AUDIO_PATH)\n",
    "\n",
    "for folder in tqdm(list_of_dirs):\n",
    "    root = AUDIO_PATH + folder\n",
    "    prev_name = folder\n",
    "    new_name = id2name[folder]\n",
    "    os.rename(AUDIO_PATH + prev_name, AUDIO_PATH + new_name)\n",
    "\n",
    "### VIDEO ###\n",
    "list_of_dirs = os.listdir(VIDEO_TXT_PATH)\n",
    "\n",
    "for folder in tqdm(list_of_dirs):\n",
    "    root = VIDEO_TXT_PATH + folder\n",
    "    prev_name = folder\n",
    "    new_name = id2name[folder]\n",
    "    os.rename(VIDEO_TXT_PATH + prev_name, VIDEO_TXT_PATH + new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case: real Celebrity's name to id001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:00<00:00, 82966.88it/s]\n",
      "100%|██████████| 1251/1251 [00:00<00:00, 101819.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# name2id = meta.set_index('VGGFace1 ID')['VoxCeleb1 ID'].to_dict()\n",
    "\n",
    "# ### AUDIO ###\n",
    "# list_of_dirs = os.listdir(AUDIO_PATH)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = AUDIO_PATH + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = name2id[folder]\n",
    "#     os.rename(AUDIO_PATH + prev_name, AUDIO_PATH + new_name)\n",
    "    \n",
    "# ### TEXTUAL VIDEO (txt) ###\n",
    "# list_of_dirs = os.listdir(VIDEO_TXT_PATH)\n",
    "\n",
    "# for folder in tqdm(list_of_dirs):\n",
    "#     root = VIDEO_TXT_PATH + folder\n",
    "#     prev_name = folder\n",
    "#     new_name = name2id[folder]\n",
    "#     os.rename(VIDEO_TXT_PATH + prev_name, VIDEO_TXT_PATH + new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `txt` and `video` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23748it [00:26, 912.42it/s] \n"
     ]
    }
   ],
   "source": [
    "for src_dir, dirs, files in tqdm(os.walk(VIDEO_TXT_PATH)):\n",
    "    dst_dir = src_dir.replace(VIDEO_TXT_PATH, VIDEO_PATH, 1)\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    for file_ in files:\n",
    "        src_file = os.path.join(src_dir, file_)\n",
    "        dst_file = os.path.join(dst_dir, file_)\n",
    "        if os.path.exists(dst_file):\n",
    "            os.remove(dst_file)\n",
    "        shutil.move(src_file, dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tracks from `voice_set_labels.txt` (i.e. dataset) which does not have frames in `zippedFaces.tar.gz`. The authors mention: _\"we should never have more than 20 frames in a sequence from the same track\"_ is taken into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_PATH = os.path.join(DATA_PATH, 'Splits/voice_set_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153486/153486 [03:35<00:00, 711.91it/s]\n"
     ]
    }
   ],
   "source": [
    "## outputs unique tracks that have at least one frame missing. \n",
    "\n",
    "tracks_to_filter_path = os.path.join(DATA_PATH, 'Splits/tracks_to_filter.txt')\n",
    "index_to_cut_filepath = len(os.path.join(DATA_PATH + 'video')) + 1\n",
    "\n",
    "tracks_to_filter = []\n",
    "\n",
    "voice_set_labels = pd.read_table(SPLIT_PATH, sep=' ', names=['path', 'phase'])\n",
    "voice_set_labels.replace({'_000': '/0', '.wav$': ''}, inplace=True, regex=True)\n",
    "\n",
    "for path in tqdm(voice_set_labels['path']):\n",
    "    video_path = os.path.join(VIDEO_PATH, path + '.txt')\n",
    "    \n",
    "    if os.path.isfile(os.path.join(DATA_PATH, 'audio', path + '.wav')):\n",
    "        frames = pd.read_table(video_path, skiprows=6, usecols=['FRAME '])\n",
    "        \n",
    "    earliest = frames['FRAME '].iloc[0]\n",
    "    latest = frames['FRAME '].iloc[-1]\n",
    "    frame_list = np.arange(earliest, latest+1)\n",
    "    mask = np.where(frame_list % 25 == 0)\n",
    "    frames_sec = frame_list[mask]\n",
    "    # only 20 per each face-track (see the asterics on the project page)\n",
    "    # frames_sec = frame_list[mask]\n",
    "    frames_sec = frame_list[mask][:20]\n",
    "    \n",
    "    for frame_number in frames_sec:\n",
    "        filename ='{0:07d}.jpg'.format(frame_number)\n",
    "        selected_frame_path = os.path.join(DATA_PATH, 'video', path[:-5] + filename)\n",
    "        \n",
    "        if os.path.isfile(selected_frame_path):\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            # remove dir path and file extention\n",
    "            tracks_to_filter.append(video_path[index_to_cut_filepath:])\n",
    "            break\n",
    "            \n",
    "with open(tracks_to_filter_path, 'w') as out_f:\n",
    "    for file in tracks_to_filter:\n",
    "        out_f.write(file + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "153486 - len(tracks_to_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "mask = voice_set_labels['path'].apply(lambda x: x + '.txt' in tracks_to_filter)\n",
    "indices = voice_set_labels[mask].index\n",
    "print('{}'.format(len(indices)))\n",
    "\n",
    "filteredpath = os.path.join(DATA_PATH, 'Splits', 'filtered_voice_set_labels.txt')\n",
    "\n",
    "with open(SPLIT_PATH, 'r') as r, open(filteredpath, 'w') as w:\n",
    "    \n",
    "    for idx, line in enumerate(r.readlines()):\n",
    "        \n",
    "        if idx not in indices:\n",
    "            w.write(line)\n",
    "        \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    151\n",
      "3      2\n",
      "Name: phase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## which phases the missing files belong to (1 and 3 -- train and seen test)\n",
    "print(voice_set_labels[mask]['phase'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
